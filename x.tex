\subsection{k-means聚类算法}

k-means是划分方法中较经典的聚类算法之一。由于该算法的效率高，所以在对大规模数据进行聚类时被广泛应用。目前，许多算法均围绕着该算法进行扩展和改进。

k-means算法以$k$为参数，把$n$个对象分成$k$个簇，使簇内具有较高的相似度，而簇间的相似度较低。k-means算法的处理过程如下：首先，随机地 选择$k$个对象，每个对象初始地代表了一个簇的平均值或中心;对剩余的每个对象，根据其与各簇中心的距离，将它赋给最近的簇;然后重新计算每个簇的平均值。 这个过程不断重复，直到准则函数收敛。通常，采用平方误差准则，其定义如下：

$$
E=\sum_{i=1}^{k}\sum_{p\in C_i}\left\|p-m_i\right\|^2
$$

这里$E$是数据中所有对象的平方误差的总和，$p$是空间中的点，$m_i$是簇$C_i$的平均值[9]。该目标函数使生成的簇尽可能紧凑独立，使用的距离度量是欧几里得距离，当然也可以用其他距离度量。

算法流程：

输入：包含$n$个对象的数据和簇的数目$k$；

输出：$n$个对象到$k$个簇，使平方误差准则最小。

步骤：

\begin{enumerate}\itemsep0em 
		\item 任意选择k个对象作为初始的簇中心；
		\item 根据簇中对象的平均值，将每个对象(重新)赋予最类似的簇；
		\item 更新簇的平均值，即计算每个簇中对象的平均值；
		\item 重复步骤(2)、(3)直到簇中心不再变化；
\end{enumerate}

\subsection{层次聚类算法}


根据层次分解的顺序是自底向上的还是自上向下的，层次聚类算法分为凝聚的层次聚类算法和分裂的层次聚类算法。

凝聚型层次聚类的策略是先将每个对象作为一个簇，然后合并这些原子簇为越来越大的簇，直到所有对象都在一个簇中，或者某个终结条件被满足。绝大多数层次聚类属于凝聚型层次聚类，它们只是在簇间相似度的定义上有所不同。


算法流程：(注：以采用最小距离的凝聚层次聚类算法为例)

\begin{enumerate}\itemsep0em 
		\item 将每个对象看作一类，计算两两之间的最小距离；
		\item 将距离最小的两个类合并成一个新类；
		\item 重新计算新类与所有类之间的距离；
		\item 重复2、3，直到所有类最后合并成一类。
\end{enumerate}

\subsection{SOM聚类算法}

SOM神经网络[11]是由芬兰神经网络专家 Kohonen 教授提出的，该算法假设在输入对象中存在一些拓扑结构或顺序，可以实现从输入空间($n$维)到输出平面($2$维)的降维映射，其映射具有拓扑特征保持性质,与实际的大脑处理有很强的理论联系。

SOM网络包含输入层和输出层。输入层对应一个高维的输入向量，输出层由一系列组织在$2$维网格上的有序节点构成，输入节点与输出节点通过权重向量连接。 学习过程中，找到与之距离最短的输出层单元，即获胜单元，对其更新。同时，将邻近区域的权值更新，使输出节点保持输入向量的拓扑特征。

算法流程：

\begin{enumerate}\itemsep0em 
		\item 网络初始化，对输出层每个节点权重赋初值；
		\item 从输入样本中随机选取输入向量并且归一化，找到与输入向量距离最小的权重向量；
		\item 定义获胜单元，在获胜单元的邻近区域调整权重使其向输入向量靠拢；
		\item 提供新样本、进行训练；
		\item 收缩邻域半径、减小学习率、重复，直到小于允许值，输出聚类结果。
\end{enumerate}
